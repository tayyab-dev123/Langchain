{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"inference_api_key\"] = os.getenv(\"inference_api_key\")\n",
    "\n",
    "llm = ChatGroq(model='llama3-70b-8192', api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikipedia\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'C:\\\\Users\\\\Tayyab\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=400))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wikipedia Tool\n",
    "wiki_api_wrapper=WikipediaAPIWrapper(top_k_results=1, lang='en', doc_content_chars_max='400')\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "wiki_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID 4fb8a355-d02f-456d-8920-d670ec06d180, but expected {'tool'} run.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to search for information about LangSmith using the Langsmith_search tool.\n",
      "\n",
      "Action: Langsmith_search\n",
      "Action Input: \"What is LangSmith?\"\u001b[0m\u001b[36;1m\u001b[1;3mGet started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID 14fb689c-2a30-497c-9856-7b3cbd145c89, but expected {'tool'} run.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mIt seems like the output is not providing a clear answer to the question. However, I can try to search again with a different query.\n",
      "\n",
      "Action: Langsmith_search\n",
      "Action Input: \"LangSmith description\"\u001b[0m\u001b[36;1m\u001b[1;3mGet started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID 6b51a0b2-760f-4e69-b58d-ef841979ddc5, but expected {'tool'} run.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mIt seems like the Langsmith_search tool is not providing a clear answer to the question. The output is just repeating the phrase \"Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\" without providing any meaningful information.\n",
      "\n",
      "Action: Langsmith_search\n",
      "Action Input: \"What is LangSmith used for?\"\u001b[0m\u001b[36;1m\u001b[1;3mGet started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_tool_end callback: TracerException(\"Found chain run at ID 3200169a-3027-4128-b01a-161cd1eca298, but expected {'tool'} run.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mIt seems like the Langsmith_search tool is not providing a clear answer to the question. The output is just repeating the phrase \"Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\" without providing any meaningful information.\n",
      "\n",
      "Action: Langsmith_search\n",
      "Action Input: \"LangSmith purpose\"\u001b[0m\u001b[36;1m\u001b[1;3mGet started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the Langsmith_search tool is not providing a clear answer to the question. The output is just repeating the phrase \"Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\" without providing any meaningful information.\n",
      "\n",
      "Final Answer: Unfortunately, I was unable to find a clear answer to the question \"What is LangSmith?\" using the Langsmith_search tool.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is LangSmith?',\n",
       " 'output': 'Unfortunately, I was unable to find a clear answer to the question \"What is LangSmith?\" using the Langsmith_search tool.'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #WebBasedRetrieverTool\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.vectorstores import FAISS, Chroma\n",
    "# from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "# from langchain.agents import AgentExecutor\n",
    "\n",
    "# loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "# docs = loader.load()\n",
    "# documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "# vector_store = Chroma.from_documents(documents, GPT4AllEmbeddings(model_name=\"all-MiniLM-L6-v2.gguf2.f16.gguf\"))\n",
    "# retriever = vector_store.as_retriever()\n",
    "# retriever_tool = create_retriever_tool(retriever=retriever, name=\"Langsmith_search\",description=\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n",
    "# retriever_tool\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "\n",
    "# Load documents from the web\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "# Create vector store and retriever tool\n",
    "vector_store = Chroma.from_documents(documents, GPT4AllEmbeddings(model_name=\"all-MiniLM-L6-v2.gguf2.f16.gguf\"))\n",
    "retriever = vector_store.as_retriever()\n",
    "retriever_tool = create_retriever_tool(retriever=retriever, name=\"Langsmith_search\", description=\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n",
    "\n",
    "# Load the prompt\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Create the react agent\n",
    "agent = create_react_agent(llm=llm, prompt=prompt, tools=[retriever_tool])\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[retriever_tool], verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\":\"What is LangSmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=1, load_all_available_meta=False, doc_content_chars_max=400, arxiv_result=<class 'arxiv.Result'>))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install arxiv\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=1, load_max_docs=1,doc_content_chars_max=400)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)\n",
    "arxiv_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001C70F15A5C0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GPT4AllEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C7D2B1A2D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001C70F15A8E0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GPT4AllEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C7D2B1A2D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Won't work when TavilySearch free tier limit reached\n",
    "\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# search = TavilySearchResults(max_results=2)\n",
    "#Combining all the tools\n",
    "tools = [retriever_tool]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install langchainhub\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': \"Langsmith_search(query: 'str', *, retriever: 'BaseRetriever' = VectorStoreRetriever(tags=['Chroma', 'GPT4AllEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C7D2B1A2D0>), document_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator: 'str' = '\\\\n\\\\n', callbacks: 'Callbacks' = None) -> 'str' - Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\", 'tool_names': 'Langsmith_search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C7D2B4B990>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C7D2A0A690>, model_name='llama3-70b-8192', groq_api_key=SecretStr('**********')), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='Langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001C70F15A5C0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GPT4AllEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C7D2B1A2D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001C70F15A8E0>, retriever=VectorStoreRetriever(tags=['Chroma', 'GPT4AllEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C7D2B1A2D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "agent = create_react_agent(llm=llm, prompt=prompt,tools=tools)\n",
    "\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "# agent_executor.invoke({\"input\": \"what is LangSmith?\"})\n",
    "agent_executor=AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
